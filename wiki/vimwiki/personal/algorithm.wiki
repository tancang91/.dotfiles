= String =
== Substring search ==
%% Summary
N: length of a _string_
M: length of a _pattern string_
i: index of a string
j: index of a pattern string (currently match)

| _Name_      | _Time complex_ |
| Brute force | O (M.N)        |
| KMP         | O (M+N)        |

%date @created Sat, 2020-Feb-29 14:51
=== Brute force ===
In normal string such as english word. This algorithm works quite well despite time complexity O(M.N). But in degenerate string, like _patern 'AAAB' 
and 'AAAAAAAB'_ this algorithm will very slow.

{{{python
def brutefore(s: str, pat: str) -> int:
    M: int = len(pat)
    N: int = len(s)
    for i in range(M-N):
        j: int = 0
        for j in range(M):
            if pat[j] != s[i+j]: break
        if j == (M-1): return i
    return N
}}}

=== Knuth-Morris-Pratt ===
NOTE: Key is _dfa table_. It treats j as the state of the dfa. At the state j, the machine take the character s[i] input to determine the next state 
of the machine as following:
    * If s[i] == pattern[j], dfa move to next state j+1
    * It s[i] != pattern[j], dfa will go back to previous state depend on char s[i]

DFA table
|   | 0 | 1 | 2 | 3 | 4 | 5 |  <- state j
|   | A | B | A | B | A | C | 
-----------------------------
| A | 1 | 1 | 3 | 1 | 5 | 1 |
| B | 0 | 2 | 0 | 4 | 0 | 4 |
| C | 0 | 0 | 0 | 0 | 0 | 0 |

*Property*
    - The algorithm requires the build-up dfa table up front which can be complicated. The linear time wworst case guarantee provided by KMP is 
        significant theoretical resultbut in practice not much compare to brute-force method.
    - Since input string never backup, it is more convenient for input stream.

{{{python
def search(s: str, pat: str) -> int:
    N: int = len(s)
    M: int = len(pat)
    dfa = build_dfa(pat)
    i = j = 0
    while i < N and j < M:
        c: str = s[i]
        j = dfa[c][j] # Update next state
        i += 1
    if j == M: return i-M
    return N

def build_dfa(pat: str):
    dfa = [[]]
    M: int = len(pat)
    dfa[pat[0]][0] = 1
    restart_state: int = 0
    for j in range(1,M):
        for c in range(0,256):
            dfa[c][j] = dfa[c][restart_state]
        dfa[pat[j]][j] = j+1
        restart_state= dfa[pat[j]][restart_state]
    return dfa
}}}


= Dynamic programming =

 %%From [[https://bit.ly/2Iy09r2|Erik Demaine]]
DP problems sometimes equivalent to:
    1. Careful brutefore.
    2. Guessing + recursion + memoization.
    3. Shortest path in some DAG (directly acyclic graph)
Time = #subproblems * time/subproblems

5 easy steps for DP problems.
    1. Define subproblems. -> # subproblems
    2. Guessing (part of solution) -> Number of choices.
    3. Relate subproblem solutions -> Time/subproblems.
    4. Recurrence & memoize or build DP table -> Check subproblem have DAG (have topoligical order)
    5. Solve original problem.

Note _Weighted interval scheduling_ (Algorithm book)
%% Assume f(1) < f(2) < .. < f(n) non-decreasing sorted finish time 
%% p(j): for interval j, to be the index i < j  such that i and j disjoint

